{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACI COLORIZATION NOTEBOOK\n",
    "\n",
    "## S. Sharma \n",
    "## March 6, 2023 (based off initial script from 11/2021)\n",
    "### For Python version 3.8.12 \n",
    "\n",
    "This notebook is for \"colorizing\" autofocus context imager (ACI) images from SHERLOC. The colorization process essentially finds and matches keypoints between the ACI (grayscale) image and the WATSON (color) image of the same target and blends the colors, providing a kind of \"merge\" product. This is useful because ACI images are co-boresighted with the SHERLOC spectrometer and are the highest resolution, thus providing both spectral mapping and textural information. By contrast, the WATSON images are color images that are taken from different standoff distances and under various illumination conditions, thus providing information about the color of rock targets useful for mineral/rock type identification. The colorized ACI is a composite product that provides both color and texture information, and SHERLOC spectral maps can be overlaid on it for spectral-textural correlation. \n",
    "\n",
    "Notes:\n",
    "\n",
    "* This notebook can be used with PIXL MCC images as well, which are similarly grayscale and provide XRF spatial mapping information. \n",
    "* This process works best abraded surface images, because more keypoints are found. It does not work well with natural surfaces. \n",
    "* OpenCV uses BGR space; matplotlib uses RGB so a color conversion is required to display images here. \n",
    "\n",
    "The steps of the notebook as are follows:\n",
    "\n",
    "1. SETUP: Import all packages.\n",
    "2. LABEL AND SHOW IMAGES: Each image is imported and displayed. The user should provide full paths to each.  \n",
    "3. CONVERT IMAGES TO GRAY: Convert all images to grayscale.\n",
    "4. DETECTOR: Create keypoints on each image using the BRISK keypoint detector and descriptor extractor (https://docs.opencv.org/3.4/de/dbf/classcv_1_1BRISK.html), and draw them and display the annotated images. \n",
    "5. FIND MATCHES: Using a FLANN-based matcher, find the number of matches between the ACI and each WATSON candidate. Draw these between images. \n",
    "6. APPLY: Apply the matches to find homography between images, warp, and generate the colorized ACI. Save product in the same folder that the notebook is in. \n",
    "\n",
    "References and Links:\n",
    "\n",
    "1. Stefan Leutenegger, Margarita Chli, and Roland Yves Siegwart. Brisk: Binary robust invariant scalable keypoints. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages 2548â€“2555. IEEE, 2011.\n",
    "2. https://docs.opencv.org/3.4/ \n",
    "3. David G. Lowe. Distinctive Image Features from Scale-Invariant Keypoints. International Journal of Computer Vision, 2004. \n",
    "4. Vino Mahendran. Feature detection and matching with OpenCV. Francium Tech Blog, 2020. https://blog.francium.tech/feature-detection-and-matching-with-opencv-5fd2394a590. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SETUP\n",
    "\n",
    "Here, the Jupyter notebook is initialized and each needed library/module is imported. Absolute imports are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "# Setup\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"All packages imported\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SET PATHS AND SHOW IMAGES\n",
    "\n",
    "ACI and WATSONs of choice are imported and displayed. Insert the full path of the ACI as the src_img_path variable (replace current text with the correct path), and the full path of the WATSON as dest_img_path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_path = '/Users/susharma/Documents/M2020/Projects/SIDNEY/DATA/SRLC/Bellegarde/ACI/SC3_0186_0683476704_113ECM_N0070000SRLC10500_0000LMJ01.PNG'\n",
    "watson_path = '/Users/susharma/Documents/M2020/Projects/SIDNEY/DATA/SRLC/Bellegarde/WATSON/ASRLC_SOL0185NIAL_0683368184_652_0070000_SRLC00720__000ECM_J02.png'\n",
    "aci = cv2.imread(aci_path)\n",
    "watson = cv2.imread(watson_path)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(aci, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Original ACI')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.imshow(cv2.cvtColor(watson, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Original WATSON')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CONVERT IMAGES TO GRAYSCALE\n",
    "\n",
    "Convert to grayscale space. The minimum number of matches that is accepted can be changed here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watson_color = watson.copy()\n",
    "watson = cv2.cvtColor(watson, cv2.COLOR_BGR2GRAY)\n",
    "aci = cv2.cvtColor(aci, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "min_matches = 37"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DETECTOR\n",
    "\n",
    "Create keypoints on each image using the BRISK keypoint detector and descriptor extractor (https://docs.opencv.org/3.4/de/dbf/classcv_1_1BRISK.html), and draw them and display the annotated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = cv2.BRISK_create()\n",
    "kp1, des1 = detector.detectAndCompute(watson, None)\n",
    "kp2, des2 = detector.detectAndCompute(aci, None)\n",
    "kp1_img = cv2.drawKeypoints(watson, kp1, None, color=(255,255,0))\n",
    "kp2_img = cv2.drawKeypoints(aci, kp2, None, color=(255,255,0))\n",
    "\n",
    "plt.close()\n",
    "plt.imshow(kp1_img)\n",
    "plt.axis('off')\n",
    "plt.title('Keypoints on WATSON')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.imshow(kp2_img)\n",
    "plt.axis('off')\n",
    "plt.title('Keypoints on ACI')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. FIND MATCHES\n",
    "\n",
    "Using a FLANN-based matcher, find the number of matches between the ACI and each WATSON candidate. Draw these between images. The distance value can be changed here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = dict(algorithm=6,\n",
    "                    table_number=6,\n",
    "                    key_size=12,\n",
    "                    multi_probe_level=2)\n",
    "search_params = {}\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "img_matches = cv2.drawMatchesKnn(watson,kp1,aci,kp2,matches[:10],None,flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "plt.close()\n",
    "plt.imshow(img_matches)\n",
    "plt.axis('off')\n",
    "plt.title('Matches')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "print('Number of Matches:')\n",
    "print(len(good_matches))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. APPLY \n",
    "\n",
    "Apply the matches to find homography between images, warp, and generate the colorized ACI. Save product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(good_matches) > min_matches:\n",
    "    print('I can colorize this, probably')\n",
    "    src_points = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_points = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    m, mask = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 5.0)\n",
    "    colorized_aci = cv2.warpPerspective(watson_color, m, (aci.shape[1], aci.shape[0]))\n",
    "    colorized_aci = cv2.cvtColor(colorized_aci, cv2.COLOR_BGR2HSV)\n",
    "    colorized_aci[:,:,2] = aci.astype(np.uint8)\n",
    "    colorized_aci = cv2.cvtColor(colorized_aci, cv2.COLOR_HSV2BGR)\n",
    "    plt.close()\n",
    "    plt.imshow(cv2.cvtColor(colorized_aci, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('I cannot colorize, here is your original image')\n",
    "    plt.close()\n",
    "    plt.imshow(cv2.cvtColor(aci, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('colorized_aci.png', colorized_aci)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
